{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a local model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script shows how to load a local model .h5 using our modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a file named as cofigure.json in the /doc path. The methods implemented in our modules uses this file to load configures values that will be used, values as model type, nodes, epochs to train, data test size and others. Things like fitted models path and a remote model path are configure there too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ncovid\": \"ML COVID-19 configure file\",\n",
      "    \"author\": \"NatalNet NCovid\",\n",
      "    \"published_at\": 2021,\n",
      "    \"folder_configs\": {\n",
      "        \"docs_path\": \"../doc/\",\n",
      "        \"data_path\": \"../dbs/\",\n",
      "        \"model_path\": \"fitted_model/\",\n",
      "        \"model_path_remote\": \"https://\",\n",
      "        \"glossary_file\": \"glossary.json\"\n",
      "    },\n",
      "    \"model_configs\": {\n",
      "        \"type_used\": \"Artificial\",\n",
      "        \"is_predicting\": \"False\",\n",
      "        \"Artificial\": {\n",
      "            \"model\": \"lstm\",\n",
      "            \"nodes\": 300,\n",
      "            \"epochs\": 100,\n",
      "            \"dropout\": 0.1,\n",
      "            \"batch_size\": 64,\n",
      "            \"earlystop\": 30,\n",
      "            \"is_output_in_input\": \"True\",\n",
      "            \"data_configs\": {\n",
      "                \"is_accumulated_values\": \"False\",\n",
      "                \"is_apply_moving_average\": \"True\",\n",
      "                \"window_size\": 7,\n",
      "                \"data_test_size_in_days\": 35,\n",
      "                \"type_norm\": \"\"\n",
      "            },\n",
      "            \"Autoregressive\": {\n",
      "                \"model\": \"arima\",\n",
      "                \"p\": 1,\n",
      "                \"d\": 1,\n",
      "                \"q\": 1\n",
      "            },\n",
      "            \"Epidemiological\": {\n",
      "                \"model\": \"sir\",\n",
      "                \"s_initial\": 100,\n",
      "                \"i_initial\": 1,\n",
      "                \"e_initial\": 1,\n",
      "                \"r_initial\": 0,\n",
      "                \"d_initial\": 0\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This is a configure.json file example.\n",
    "import json\n",
    "\n",
    "# Load the local configure.json and print it\n",
    "configure_json = open('../doc/configure.json', 'r')\n",
    "print(json.dumps(json.load(configure_json), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load this set of configurations, import the configs_manner.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model infos: \n",
      " {'model_nodes': 300, 'model_epochs': 100, 'model_dropout': 0.1, 'model_batch_size': 64, 'model_earlystop': 30, 'model_is_output_in_input': True, 'data_is_accumulated_values': False, 'data_is_apply_moving_average': True, 'data_window_size': 7, 'data_test_size_in_days': 35, 'data_type_norm': ''}\n",
      "\n",
      "\n",
      "Models path: \n",
      " ../dbs/fitted_model/\n"
     ]
    }
   ],
   "source": [
    "# If this script is running in another folder, change the base path to the /src folder.\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import configs_manner\n",
    "\n",
    "# Priting some configures variabels.\n",
    "print(\"Model infos: \\n\", configs_manner.model_infos)\n",
    "print(\"\\n\")\n",
    "print(\"Models path: \\n\", configs_manner.model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure any path model param, just change the value in the configure.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a model constructor, is needed to collect and create a dataset construct before, because the modelus has to know some information to create the model archtecture automatically (deppending of the number of data features). \n",
    "\n",
    "In this script it'll be do a remote data request, so before to create a data constructor, it is necessary declare the remote repository, the locality, the features to get, also the start and finish date. So, we need to create a data constructor and use a collect method. For more details see [Loading remote data](loading_remote_data.ipynb) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specif code to the remote repository data.\n",
    "repo = \"p971074907\"\n",
    "# coutry and state acronym splited by a \":\"\n",
    "path = \"brl:rn\"\n",
    "# columns (or features) to be extracted from the database, each one splited by a \":\"\n",
    "feature = \"date:newDeaths:newCases:\"\n",
    "# start date for the data request.\n",
    "begin = \"2020-05-01\"\n",
    "# finish date for the data request.\n",
    "end = \"2021-07-01\"\n",
    "\n",
    "# import the data_manner.py file. (taking into account that you are in src/ path)\n",
    "import data_manner\n",
    "\n",
    "# creating the DataConstructor instance\n",
    "data_constructor = data_manner.DataConstructor()\n",
    "# collect data from the remote repository.\n",
    "collected_data = data_constructor.collect_dataframe(path, repo, feature, begin, end)\n",
    "\n",
    "# building the data test to set up the number of features to model model archtecture.\n",
    "test = data_constructor.build_test(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a model instance, it's needed to import the desired model manner file and call the creating() method to mount the model architecture. In this example it'll be used a LSTM model. See [Creating a model](creating_a_model.ipynb) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Model\n",
      "\tinput, output and timesteps: 7\n",
      "\tlstm nodes: 300\n",
      "\tfeatures: 2\n",
      "\tdropout: 0.1\n"
     ]
    }
   ],
   "source": [
    "# import the lstm_manner.py file. (taking into account that you are in src/ path)\n",
    "from models.artificial import lstm_manner\n",
    "\n",
    "# creating  a model instance\n",
    "lstm_model = lstm_manner.ModelLSTM(path)\n",
    "# set up the model architecture\n",
    "lstm_model.creating()\n",
    "print(lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load local model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a desired model o have to know it uuid. To see it, open the metadata.json created when you saved ([Training and saving model](training_and_saving_a_model.ipynb)) the model and find \"model_id\". Also, you can see the .h5 file name in the fitted models path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.loading(\"cee94ec2-ac6e-11ec-84ad-48a47252b4f8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method laods the trained weights from saved model and makes the new instance equal as the trained."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b48a8372de07dcfb7270582fe52a873b16bfa1fa9f9ee7b27a1873baaed48200"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ncovid-backend')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
