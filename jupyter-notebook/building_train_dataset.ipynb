{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script shows how to build a train dataset using our modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a file named as cofigure.json in the /doc path. The methods implemented in our modules uses this file to load configures values that will be used, values as model type, nodes, epochs to train, data test size and others. Things like window data size, data accumulated or moving average application are configure there too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ncovid\": \"ML COVID-19 configure file\",\n",
      "    \"author\": \"NatalNet NCovid\",\n",
      "    \"published_at\": 2021,\n",
      "    \"folder_configs\": {\n",
      "        \"docs_path\": \"../doc/\",\n",
      "        \"data_path\": \"../dbs/\",\n",
      "        \"model_path\": \"fitted_model/\",\n",
      "        \"model_path_remote\": \"https://\",\n",
      "        \"glossary_file\": \"glossary.json\"\n",
      "    },\n",
      "    \"model_configs\": {\n",
      "        \"type_used\": \"Artificial\",\n",
      "        \"is_predicting\": \"False\",\n",
      "        \"Artificial\": {\n",
      "            \"model\": \"lstm\",\n",
      "            \"nodes\": 300,\n",
      "            \"epochs\": 100,\n",
      "            \"dropout\": 0.1,\n",
      "            \"batch_size\": 64,\n",
      "            \"earlystop\": 30,\n",
      "            \"is_output_in_input\": \"True\",\n",
      "            \"data_configs\": {\n",
      "                \"is_accumulated_values\": \"False\",\n",
      "                \"is_apply_moving_average\": \"True\",\n",
      "                \"window_size\": 7,\n",
      "                \"data_test_size_in_days\": 35,\n",
      "                \"type_norm\": \"\"\n",
      "            },\n",
      "            \"Autoregressive\": {\n",
      "                \"model\": \"arima\",\n",
      "                \"p\": 1,\n",
      "                \"d\": 1,\n",
      "                \"q\": 1\n",
      "            },\n",
      "            \"Epidemiological\": {\n",
      "                \"model\": \"sir\",\n",
      "                \"s_initial\": 100,\n",
      "                \"i_initial\": 1,\n",
      "                \"e_initial\": 1,\n",
      "                \"r_initial\": 0,\n",
      "                \"d_initial\": 0\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This is a configure.json file example.\n",
    "import json\n",
    "\n",
    "# Load the local configure.json and print it\n",
    "configure_json = open('../doc/configure.json', 'r')\n",
    "print(json.dumps(json.load(configure_json), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load this set of configurations, import the configs_manner.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data window size: \n",
      " 7\n",
      "\n",
      "\n",
      "If data is accumulated: \n",
      " False\n",
      "\n",
      "\n",
      "If is the moving average applied: \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "# If this script is running in another folder, change the base path to the /src folder.\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import configs_manner\n",
    "\n",
    "# Priting some configures variabels.\n",
    "print(\"Data window size: \\n\", configs_manner.model_infos[\"data_window_size\"])\n",
    "print(\"\\n\")\n",
    "print(\"If data is accumulated: \\n\", configs_manner.model_infos[\"data_is_accumulated_values\"])\n",
    "print(\"\\n\")\n",
    "print(\"If is the moving average applied: \\n\", configs_manner.model_infos[\"data_is_apply_moving_average\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure any data param, just change the value in the configure.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script it'll be do a remote data request, so before to create a data constructor, it is necessary declare the remote repository, the locality, the features to get, and the start and finish date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specif code to the remote repository data.\n",
    "repo = \"p971074907\"\n",
    "# coutry and state acronym splited by a \":\"\n",
    "path = \"brl:rn\"\n",
    "# columns (or features) to be extracted from the database, each one splited by a \":\"\n",
    "feature = \"date:newDeaths:newCases:\"\n",
    "# start date for the data request.\n",
    "begin = \"2020-05-01\"\n",
    "# finish date for the data request.\n",
    "end = \"2021-07-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our modules, almost all procedures uses class objects and class methods. To get a dataset from a remote repository, firstly create a DataConstructor constructor and call the .collect_dataframe() method. See [Loading remote data](loading_remote_data.ipynb) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data_manner.py file. (taking into account that you are in src/ path)\n",
    "import data_manner\n",
    "\n",
    "# creating the DataConstructor instance\n",
    "data_constructor = data_manner.DataConstructor()\n",
    "# collect data from the remote repository.\n",
    "collected_data = data_constructor.collect_dataframe(path, repo, feature, begin, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally some data processings is done to deal with the data variation, like moving avarage or data difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the collected data, call the .build_train() method to create a data train in the right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain X and Train target shapes:  (413, 7, 2) (413, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "train = data_constructor.build_train(collected_data)\n",
    "\n",
    "print(\"Tain X and Train target shapes: \", train.x.shape, train.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b48a8372de07dcfb7270582fe52a873b16bfa1fa9f9ee7b27a1873baaed48200"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ncovid-backend')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
