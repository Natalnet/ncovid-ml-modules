{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating N times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates how to evaluate a model N times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate a model, you'll have to build a train dataset from local or remote data. For more details see [Building train dataset](building_train_dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# specif code to the remote repository data.\n",
    "repo = \"p971074907\"\n",
    "# coutry and state acronym splited by a \":\"\n",
    "path = \"brl:rn\"\n",
    "# columns (or features) to be extracted from the database, each one splited by a \":\"\n",
    "feature = \"date:newDeaths:newCases:\"\n",
    "# start date for the data request.\n",
    "begin = \"2020-05-01\"\n",
    "# finish date for the data request.\n",
    "end = \"2021-07-01\"\n",
    "\n",
    "# import the data_manner.py file. (taking into account that you are in src/ path)\n",
    "import data_manner\n",
    "\n",
    "# creating the DataConstructor instance\n",
    "data_constructor = data_manner.DataConstructor()\n",
    "# collect data from the remote repository.\n",
    "collected_data = data_constructor.collect_dataframe(path, repo, feature, begin, end)\n",
    "\n",
    "# building the data train to set up the number of features to model model archtecture.\n",
    "train = data_constructor.build_train(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to remark that the ```configure.json``` file info ```\"data_test_size_in_days\"``` will decide the number of test days that the method will take into account when to extract the metric values from the train and for the test. To this example, the ```\"data_test_size_in_days\"``` value has been set up to 35 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be necessary to create a test dataset to calculate the metrics. For more details, see [Building test dataset](building_test_dataset.ipynb). The input arguments to the ```.build_test()``` method it'll be the same as to the ```.build_train()``` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the data test to set up the number of features to model model archtecture.\n",
    "test = data_constructor.build_test(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will have to create the model instances to evaluate. Set up the number of times you want the same model architecture and generate the model instance. In this example, we'll use an LSTM model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the desired model manner\n",
    "# lstm_manner.py file. (taking into account that you are in src/ path)\n",
    "from models.artificial import lstm_manner\n",
    "\n",
    "# N times reapet the same model\n",
    "n_repeat = 2\n",
    "# model instance\n",
    "lstm_model = lstm_manner.ModelLSTM(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can create the model ``` Evaluator``` constructor. Import the ```evaluator_manner.py``` file and instantiate a constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the evaluator manner file\n",
    "import evaluator_manner\n",
    "\n",
    "# creating the evaluator constructor\n",
    "evaluator = evaluator_manner.Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, call the evaluator constructor ```.evaluate_n_models_n_times()``` method passing the model instances list, the training dataset, the test dataset, and the N times (repeat) value as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model architecture\n",
    "evaluated = evaluator.evaluate_model_n_times(\n",
    "    models=lstm_model, data_train=train, data=test, n_repeat=n_repeat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned elements are the metric values for models train and test phases for each instance of the same architecture to the chosen model. You can use this to evaluate the quality and robustness of your architecture, finding a variance according to the seed weights change."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
