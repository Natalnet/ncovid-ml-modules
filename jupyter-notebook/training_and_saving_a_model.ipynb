{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and saving a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates how to create and save a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods and modules in this example make use of information from the `configure.json` file, which is located in the `/doc` folder. Fill in the blanks in the file. Some of them are: the model type, the number of nodes, the number of epochs in the training step, the size of the data test, the size of the windowing data, checking if the data contains accumulated values, and a flag to apply the moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ncovid\": \"ML COVID-19 configure file\",\n",
      "    \"author\": \"NatalNet NCovid\",\n",
      "    \"published_at\": 2021,\n",
      "    \"folder_configs\": {\n",
      "        \"docs_path\": \"../doc/\",\n",
      "        \"data_path\": \"../dbs/\",\n",
      "        \"model_path\": \"fitted_model/\",\n",
      "        \"model_path_remote\": \"https://\",\n",
      "        \"glossary_file\": \"glossary.json\"\n",
      "    },\n",
      "    \"model_configs\": {\n",
      "        \"type_used\": \"Artificial\",\n",
      "        \"is_predicting\": \"False\",\n",
      "        \"Artificial\": {\n",
      "            \"model\": \"lstm\",\n",
      "            \"nodes\": 300,\n",
      "            \"epochs\": 100,\n",
      "            \"dropout\": 0.1,\n",
      "            \"batch_size\": 64,\n",
      "            \"earlystop\": 30,\n",
      "            \"is_output_in_input\": \"True\",\n",
      "            \"data_configs\": {\n",
      "                \"is_apply_differencing\": \"False\",\n",
      "                \"is_apply_moving_average\": \"True\",\n",
      "                \"window_size\": 7,\n",
      "                \"data_test_size_in_days\": 35,\n",
      "                \"type_norm\": \"\"\n",
      "            },\n",
      "            \"Autoregressive\": {\n",
      "                \"model\": \"arima\",\n",
      "                \"p\": 1,\n",
      "                \"d\": 1,\n",
      "                \"q\": 1\n",
      "            },\n",
      "            \"Epidemiological\": {\n",
      "                \"model\": \"sir\",\n",
      "                \"s_initial\": 100,\n",
      "                \"i_initial\": 1,\n",
      "                \"e_initial\": 1,\n",
      "                \"r_initial\": 0,\n",
      "                \"d_initial\": 0\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "configure_json = open('../doc/configure.json', 'r')\n",
    "\n",
    "import json\n",
    "print(json.dumps(json.load(configure_json), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load this set of configurations, import the configs_manner.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: \n",
      " Artificial\n",
      "\n",
      "\n",
      "Model subtype: \n",
      " lstm\n",
      "\n",
      "\n",
      "Number of model nodes: \n",
      " 300\n",
      "\n",
      "\n",
      "Model window size: \n",
      " 100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import configs_manner\n",
    "from importlib import reload\n",
    "reload(configs_manner)\n",
    "\n",
    "print(\"Model type: \\n\", configs_manner.model_type)\n",
    "print(\"\\n\")\n",
    "print(\"Model subtype: \\n\", configs_manner.model_subtype)\n",
    "print(\"\\n\")\n",
    "print(\"Number of model nodes: \\n\", configs_manner.model_infos[\"model_nodes\"])\n",
    "print(\"\\n\")\n",
    "print(\"Model window size: \\n\", configs_manner.model_infos[\"model_epochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure any data or model param, just change the value in the `configure.json` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a model, you must first collect and create a dataset, from which some information will be used to automatically build the model architecture. We're making a data request from a remote location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specif code to the remote repository data.\n",
    "repo = \"p971074907\"\n",
    "# coutry and state acronym splited by a \":\"\n",
    "path = \"brl:rn\"\n",
    "# columns (or features) to be extracted from the database, each one splited by a \":\"\n",
    "feature = \"date:newDeaths:newCases:\"\n",
    "# start date for the data request.\n",
    "begin = \"2020-05-01\"\n",
    "# finish date for the data request.\n",
    "end = \"2022-07-01\"\n",
    "\n",
    "# import the data_manner.py file. (taking into account that you are in src/ path)\n",
    "import data_manner\n",
    "\n",
    "# creating the DataConstructor instance\n",
    "data_constructor = data_manner.DataConstructor()\n",
    "# collect data from the remote repository.\n",
    "collected_data = data_constructor.collect_dataframe(path, repo, feature, begin, end)\n",
    "\n",
    "# building the data and train to set up the number of features to model model archtecture.\n",
    "train = data_constructor.build_train(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Artificial model, bound on the Artificial Neural Networks subclass, will be used in this script. It will be the well-known Long-Short Term Memory ANN that is used (LSTM). Almost all procedures in our modules make use of class objects and class methods. To begin creating a model constructor, import the manner associated with the desired mode. In this case, the `lstm manner.py` script is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the lstm_manner.py file. (taking into account that you are in src/ path)\n",
    "from models.artificial import lstm_manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model manner instance using `ModelLSTM()`, and build the architecture using the `creation()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Model\n",
      "\tinput, output and timesteps: 7\n",
      "\tlstm nodes: 300\n",
      "\tfeatures: 2\n",
      "\tdropout: 0.1\n"
     ]
    }
   ],
   "source": [
    "# creating  a model instance\n",
    "lstm_model = lstm_manner.ModelLSTM(path)\n",
    "# set up the model architecture\n",
    "lstm_model.creating()\n",
    "print(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7fde886004c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the instantiated model, call the `fitting()` model method and pass the train inputs (`train.x`) and the train targets (`train.y`) as the function args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This can take some time.\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 1490.6245\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 435.1573\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 723.4645\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 65ms/step - loss: 901.0848: 0s - los\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 534.4301\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 366.8760\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 399.7373\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 157.5640\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 193.3442\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 206.3453\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 145.2385\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 162.9285\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 187.4725\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 159.3313\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 119.3184\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 125.6088\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 160.7085\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 123.6048\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 148.1891\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 123.6043\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 110.0295\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 109.7200\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 81.7322\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 67.6304\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 78.5866\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 82.9211\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 64.0734\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 48.2593\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 45.4304\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 43.1948\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 36.2735\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 34.6532\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 33.7362\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 33.6503\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 31.6269\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 32.2094\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 32.9911\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 34.3437\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 30.6309\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 29.3175\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 29.5354\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 29.3087\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 27.3291\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 30.1535\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 32.6267\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 29.0033\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 26.8428\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 28.8627\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 27.6001\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 26.9477\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 25.0312\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 27.8839\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 28.3790\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 25.7253\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 24.4673\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 24.0543\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 25.2453\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 24.2701\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 24.9575\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 23.6932\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 25.2834\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 22.7613\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 22.5817\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 22.0464\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 22.5520\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 21.8214\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 21.7145\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 20.9063\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 25.1959\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 23.8301\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 22.5929\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 23.6925\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 21.5836\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 22.2532\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 21.7698\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 22.7384\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 21.2484\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 22.6257\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 24.2843\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 20.5746\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 20.8022\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 21.3002\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 19.1762\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 18.7236\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 19.0862\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 20.5995\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 21.0613\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 18.7731\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 20.9877\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 21.5036\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 31.6258\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 27.3607\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 22.6671\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 23.0565\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 21.7361\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 21.7089\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 24.7519\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 23.5397\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 20.3052\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 19.2169\n",
      "LSTM model trained!\n"
     ]
    }
   ],
   "source": [
    "print(\"This can take some time.\")\n",
    "lstm_model.fiting(train.x, train.y, verbose=1)\n",
    "print(\"LSTM model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the model after it has been trained, use the `saving()` method. The save method does not accept a name or any arguments. It will create a unique id for the model in the `dbs/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_apply_differencing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b0ba4058b617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"rn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"rn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Doutorado UFRN/ncovid_project/ncovid-ml-modules/src/models/model_ai_interface.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, model_name, overwrite)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id_to_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__saving_metadata_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id_to_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Model Saved\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Doutorado UFRN/ncovid_project/ncovid-ml-modules/src/models/model_ai_interface.py\u001b[0m in \u001b[0;36m__saving_metadata_file\u001b[0;34m(self, model_id, model_name)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             metadata[\"model_configs\"][\"Artificial\"][\"data_configs\"] = {\n\u001b[0;32m---> 78\u001b[0;31m                 \"is_apply_differencing\": configs_manner.model_infos[\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0;34m\"is_apply_differencing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 ],\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_apply_differencing'"
     ]
    }
   ],
   "source": [
    "lstm_model.saving(\"_\"+\"rn\")\n",
    "lstm_model.saving(\"_\"+\"rn\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will create two files: `metadata.json` and `.h5`. The `metadata.json` file will contain the model information as well as a UUID (unique identifier) that corresponds to the `.h5` file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model2 = lstm_manner.ModelLSTM('rn')\n",
    "# loading the local model\n",
    "lstm_model2.loading(\"192e04f2-c658-11ec-8f17-48a47252b4f8\")\n",
    "\n",
    "lstm_model2.saving(\"_\"+\"rn\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0aa926c7c9173752559c45e7da58d685a6b94148f8f16423c34f039b4987f0a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('my_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
